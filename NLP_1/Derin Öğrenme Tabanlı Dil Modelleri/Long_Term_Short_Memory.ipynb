{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LSTM ile **metin üretimi**"
      ],
      "metadata": {
        "id": "wovtgzwZ8jNp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7Wquw5PP6-cn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT ile veri üretimi\n",
        "texts = [\n",
        "    \"bugün hava çok güzel, dışarıda yürüyüş yapmayı planlıyorum.\",\n",
        "    \"kahvemi alıp sakin bir yerde oturmak bana iyi geliyor.\",\n",
        "    \"yeni şeyler öğrenmek beni her zaman motive eder.\",\n",
        "    \"akşam yemeğinde ev yapımı bir yemek hazırladım.\",\n",
        "    \"müzik dinlerken çalışmak daha verimli olmamı sağlıyor.\",\n",
        "    \"hafta sonu için küçük bir seyahat planı yapıyorum.\",\n",
        "    \"doğada vakit geçirmek zihnimi dinlendiriyor.\",\n",
        "    \"uzun zamandır ertelediğim kitabı sonunda okumaya başladım.\",\n",
        "    \"spor yaptıktan sonra kendimi daha enerjik hissediyorum.\",\n",
        "    \"erken uyanmak günümü daha iyi planlamama yardımcı oluyor.\",\n",
        "    \"bugün işler beklediğimden daha hızlı ilerledi.\",\n",
        "    \"arkadaşlarımla sohbet etmek moralimi yükseltiyor.\",\n",
        "    \"yeni bir diziye başladım ve oldukça sardı.\",\n",
        "    \"yoğun bir günün ardından dinlenmeye ihtiyacım var.\",\n",
        "    \"hedeflerime adım adım yaklaşmak beni mutlu ediyor.\",\n",
        "    \"sessiz bir ortamda çalışmak odaklanmamı artırıyor.\",\n",
        "    \"bugün kendime zaman ayırmaya karar verdim.\",\n",
        "    \"öğle arasında kısa bir yürüyüş yaptım.\",\n",
        "    \"yeni tarifler denemek mutfakta daha yaratıcı olmamı sağlıyor.\",\n",
        "    \"yaptığım planlara sadık kalmaya çalışıyorum.\",\n",
        "    \"bugün motivasyonum oldukça yüksekti.\",\n",
        "    \"teknoloji alanındaki gelişmeleri takip etmeyi seviyorum.\",\n",
        "    \"not almak öğrenme sürecimi kolaylaştırıyor.\",\n",
        "    \"erken yatmak ertesi gün daha dinç olmamı sağlıyor.\",\n",
        "    \"uzun vadeli hedefler belirlemek bana yön veriyor.\",\n",
        "    \"bugün biraz yorgun hissediyorum ama üretkenim.\",\n",
        "    \"güneşli havalar ruh halimi olumlu etkiliyor.\",\n",
        "    \"yeni bir beceri kazanmak için çalışıyorum.\",\n",
        "    \"zaman yönetimi konusunda kendimi geliştirmeye çalışıyorum.\",\n",
        "    \"sabahları kahve içmek benim için bir rutin.\",\n",
        "    \"yoğun tempoya rağmen dengeli kalmaya çalışıyorum.\",\n",
        "    \"bugün yapılacaklar listemi tamamladım.\",\n",
        "    \"kendime güvenim son zamanlarda arttı.\",\n",
        "    \"öğrenirken hata yapmak sürecin bir parçası.\",\n",
        "    \"küçük başarılar beni daha çok motive ediyor.\",\n",
        "    \"bugün daha pozitif düşünmeye çalıştım.\",\n",
        "    \"planlı olmak stresi azaltıyor.\",\n",
        "    \"yeni fikirler üretmek beni heyecanlandırıyor.\",\n",
        "    \"çalışma ortamımı daha düzenli hale getirdim.\",\n",
        "    \"kendimi geliştirmek için kaynaklar araştırıyorum.\",\n",
        "    \"bugün verimli bir gün geçirdim.\",\n",
        "    \"odaklanınca zamanın nasıl geçtiğini anlamıyorum.\",\n",
        "    \"hedeflerime ulaşmak için sabırlı olmam gerekiyor.\",\n",
        "    \"gün sonunda yaptıklarımı değerlendirmeyi seviyorum.\",\n",
        "    \"düzenli molalar vermek performansımı artırıyor.\",\n",
        "    \"bugün biraz daha disiplinliydim.\",\n",
        "    \"kendimle ilgili yeni şeyler fark ediyorum.\",\n",
        "    \"istikrarlı olmak uzun vadede sonuç veriyor.\",\n",
        "    \"bugünü kendim için verimli bir şekilde tamamladım.\",\n",
        "    \"bugün yapılacak işlerim beklediğimden fazlaydı.\",\n",
        "    \"sabah erken kalkmak başlangıçta zor geldi.\",\n",
        "    \"yoğun trafikte zaman kaybetmek moralimi bozdu.\",\n",
        "    \"bir süredir ertelediğim işleri tamamlamaya başladım.\",\n",
        "    \"uzun bir toplantıdan sonra zihinsel olarak yoruldum.\",\n",
        "    \"planladığım gibi gitmeyen şeyler beni düşündürdü.\",\n",
        "    \"gün içinde kısa molalar vermek iyi hissettirdi.\",\n",
        "    \"beklenmedik bir sorunla karşılaşmak canımı sıktı.\",\n",
        "    \"odaklanmakta zorlandığım bir gündü.\",\n",
        "    \"akşam eve geç dönmek beni biraz yordu.\",\n",
        "    \"bazı konularda daha sabırlı olmam gerektiğini fark ettim.\",\n",
        "    \"işleri son ana bırakmak stres seviyemi artırdı.\",\n",
        "    \"bugün zaman yönetiminde pek başarılı olamadım.\",\n",
        "    \"beklediğim geri dönüşü alamamak hayal kırıklığı yarattı.\",\n",
        "    \"yoğunluk nedeniyle kendime vakit ayıramadım.\",\n",
        "    \"yaptığım hatalardan ders çıkarmaya çalışıyorum.\",\n",
        "    \"gün içinde motivasyonum dalgalıydı.\",\n",
        "    \"bazı kararları daha dikkatli almam gerekiyor.\",\n",
        "    \"uzun süre ekrana bakmak gözlerimi yordu.\",\n",
        "    \"iş yükü arttıkça stresim de arttı.\",\n",
        "    \"bugün biraz dağınık hissettim.\",\n",
        "    \"plan dışı gelişmeler günü zorlaştırdı.\",\n",
        "    \"yorgunluk konsantrasyonumu olumsuz etkiledi.\",\n",
        "    \"beklentilerimle sonuçlar örtüşmedi.\",\n",
        "    \"bazı görevler tahminimden uzun sürdü.\",\n",
        "    \"bugün kendimi pek enerjik hissetmiyorum.\",\n",
        "    \"zamanın hızlı geçmesi işleri yetiştirmemi zorlaştırdı.\",\n",
        "    \"önceliklendirme yapmam gerektiğini fark ettim.\",\n",
        "    \"yoğun tempoda hata yapma ihtimali artıyor.\",\n",
        "    \"beklenmedik bir değişiklik planlarımı bozdu.\",\n",
        "    \"gün içinde stresle baş etmeye çalıştım.\",\n",
        "    \"bazı konular kafamı fazlasıyla meşgul etti.\",\n",
        "    \"motivasyonumu yeniden toplamak zor oldu.\",\n",
        "    \"bugün biraz isteksizdim.\",\n",
        "    \"odak kaybı verimimi düşürdü.\",\n",
        "    \"bazı sorumluluklar üst üste geldi.\",\n",
        "    \"beklediğimden daha zor bir gündü.\",\n",
        "    \"yorgunluk kararlarımı etkiledi.\",\n",
        "    \"gün sonunda zihinsel olarak tükendim.\",\n",
        "    \"işleri toparlamak zaman aldı.\",\n",
        "    \"bugün daha az üretken hissettim.\",\n",
        "    \"bazı hedefleri ertelemek zorunda kaldım.\",\n",
        "    \"stresli anlarda sakin kalmaya çalıştım.\",\n",
        "    \"yoğunluk nedeniyle planlar aksadı.\",\n",
        "    \"gün içinde motivasyonumu korumak zordu.\",\n",
        "    \"bazı konular üzerinde tekrar düşünmem gerekiyor.\",\n",
        "    \"beklentilerimle yüzleştiğim bir gündü.\",\n",
        "    \"bugün kendime karşı daha eleştireldim.\",\n",
        "    \"yapılacaklar listesi kabardıkça zorlandım.\",\n",
        "    \"günü beklediğimden daha yorgun kapattım.\",\n",
        "    \"bugünü de böylece tamamlamış oldum.\"\n",
        "]"
      ],
      "metadata": {
        "id": "BnJeW_bC9ga9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__saXfDP-crk",
        "outputId": "f8080e80-72ec-4b66-fdcc-793b8f17d551"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metin temizleme ve preprocessing\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "total_words = len(tokenizer.word_index) + 1 # toplam kelime sayısı\n",
        "print(total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI6UoiUF-ibM",
        "outputId": "c733053a-b15b-4f08-e715-7e19dde80837"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_example = texts[0]\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([text_example])\n",
        "print(\"Sequence:\", sequence)\n",
        "\n",
        "decoded = [tokenizer.index_word[i] for i in sequence[0]]\n",
        "print(\"Decoded:\", decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3popo8el_0JM",
        "outputId": "898f74bd-e457-4f9c-e8d8-5f6d2770553c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence: [[2, 92, 33, 93, 94, 34, 95, 96]]\n",
            "Decoded: ['bugün', 'hava', 'çok', 'güzel', 'dışarıda', 'yürüyüş', 'yapmayı', 'planlıyorum']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n-gram dizileri oluştur ve padding uygula\n",
        "input_sequences = []\n",
        "for text in texts:\n",
        "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "    # her metin için n-gram dizisi oluşturalım\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "print(len(input_sequences))\n",
        "print(\"\\n\",input_sequences[0])\n",
        "print(\"\\n\",input_sequences[111])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqnH8tc5_hwW",
        "outputId": "9c79724f-5ac2-44d1-eefe-19ebc3466394"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "467\n",
            "\n",
            " [2, 92]\n",
            "\n",
            " [6, 156, 157, 158, 3, 159, 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# en uzun diziyi bulalım ve hepsinin uzunluğunu aynı yapalım : padding\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')"
      ],
      "metadata": {
        "id": "8MWD9uu5_8mN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X (girdi) ve y (hedef değişken)\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]\n",
        "\n",
        "# one hot encoding\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
      ],
      "metadata": {
        "id": "gOkM3c3DAFXU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "\n",
        "model = Sequential()\n",
        "# embedding\n",
        "model.add(Embedding(total_words, 50, input_length=X.shape[1]))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(100, return_sequences=False))\n",
        "\n",
        "# Output\n",
        "model.add(Dense(total_words, activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU_WwuK5C5yz",
        "outputId": "bcd133a3-0e6b-4bf1-a784-1df897511315"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "fRxZ7P1hDo2M"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "model.fit(X, y, epochs=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQmwoyIqDzUM",
        "outputId": "a45ed59e-80e8-4318-aa29-200c2734034f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.0122 - loss: 5.9099\n",
            "Epoch 2/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0306 - loss: 5.8871\n",
            "Epoch 3/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0383 - loss: 5.7547\n",
            "Epoch 4/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0521 - loss: 5.5951\n",
            "Epoch 5/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0409 - loss: 5.5851\n",
            "Epoch 6/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0406 - loss: 5.5880\n",
            "Epoch 7/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0283 - loss: 5.5856\n",
            "Epoch 8/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0375 - loss: 5.5271\n",
            "Epoch 9/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0397 - loss: 5.4753\n",
            "Epoch 10/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0455 - loss: 5.3596\n",
            "Epoch 11/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0448 - loss: 5.2901\n",
            "Epoch 12/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0787 - loss: 5.1278\n",
            "Epoch 13/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0480 - loss: 5.1579\n",
            "Epoch 14/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0626 - loss: 5.0754\n",
            "Epoch 15/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0658 - loss: 4.9815\n",
            "Epoch 16/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0858 - loss: 4.8849\n",
            "Epoch 17/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0646 - loss: 4.8340\n",
            "Epoch 18/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0817 - loss: 4.7738\n",
            "Epoch 19/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0864 - loss: 4.6084\n",
            "Epoch 20/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0892 - loss: 4.5829\n",
            "Epoch 21/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0833 - loss: 4.5621\n",
            "Epoch 22/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0988 - loss: 4.4570\n",
            "Epoch 23/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0968 - loss: 4.3961\n",
            "Epoch 24/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1583 - loss: 4.2826\n",
            "Epoch 25/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1670 - loss: 4.1449\n",
            "Epoch 26/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1905 - loss: 4.0366\n",
            "Epoch 27/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2090 - loss: 4.0286\n",
            "Epoch 28/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2179 - loss: 3.9267\n",
            "Epoch 29/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2680 - loss: 3.7810\n",
            "Epoch 30/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2964 - loss: 3.7047\n",
            "Epoch 31/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3046 - loss: 3.6088\n",
            "Epoch 32/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3198 - loss: 3.5586\n",
            "Epoch 33/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3707 - loss: 3.4369\n",
            "Epoch 34/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4051 - loss: 3.3393\n",
            "Epoch 35/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4656 - loss: 3.1998\n",
            "Epoch 36/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4506 - loss: 3.1700\n",
            "Epoch 37/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4829 - loss: 3.0382\n",
            "Epoch 38/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5114 - loss: 2.8776\n",
            "Epoch 39/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5747 - loss: 2.8564\n",
            "Epoch 40/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5523 - loss: 2.7591\n",
            "Epoch 41/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5894 - loss: 2.6216\n",
            "Epoch 42/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6178 - loss: 2.5938\n",
            "Epoch 43/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5995 - loss: 2.5559\n",
            "Epoch 44/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6380 - loss: 2.4070\n",
            "Epoch 45/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6627 - loss: 2.3319\n",
            "Epoch 46/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6551 - loss: 2.2794\n",
            "Epoch 47/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6843 - loss: 2.2040\n",
            "Epoch 48/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6957 - loss: 2.0848\n",
            "Epoch 49/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6815 - loss: 2.0423\n",
            "Epoch 50/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6922 - loss: 2.0510\n",
            "Epoch 51/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7057 - loss: 2.0569\n",
            "Epoch 52/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7061 - loss: 1.9039\n",
            "Epoch 53/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6914 - loss: 1.8689\n",
            "Epoch 54/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7513 - loss: 1.7234\n",
            "Epoch 55/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7453 - loss: 1.6742\n",
            "Epoch 56/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7967 - loss: 1.5555\n",
            "Epoch 57/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7528 - loss: 1.6023\n",
            "Epoch 58/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8067 - loss: 1.4832\n",
            "Epoch 59/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7956 - loss: 1.4618\n",
            "Epoch 60/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7779 - loss: 1.4953\n",
            "Epoch 61/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8112 - loss: 1.4007\n",
            "Epoch 62/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7885 - loss: 1.3763\n",
            "Epoch 63/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8260 - loss: 1.3113\n",
            "Epoch 64/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8151 - loss: 1.2529\n",
            "Epoch 65/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8178 - loss: 1.2596\n",
            "Epoch 66/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8635 - loss: 1.1299\n",
            "Epoch 67/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8129 - loss: 1.2174\n",
            "Epoch 68/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8319 - loss: 1.1316\n",
            "Epoch 69/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8382 - loss: 1.1010\n",
            "Epoch 70/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8213 - loss: 1.1268\n",
            "Epoch 71/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8338 - loss: 1.0595\n",
            "Epoch 72/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8744 - loss: 0.9283\n",
            "Epoch 73/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8727 - loss: 0.9232\n",
            "Epoch 74/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8593 - loss: 0.9087\n",
            "Epoch 75/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8850 - loss: 0.9006\n",
            "Epoch 76/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8854 - loss: 0.8258\n",
            "Epoch 77/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8699 - loss: 0.8521\n",
            "Epoch 78/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8384 - loss: 0.8797\n",
            "Epoch 79/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8718 - loss: 0.8367\n",
            "Epoch 80/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8810 - loss: 0.7939\n",
            "Epoch 81/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8708 - loss: 0.7405\n",
            "Epoch 82/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8936 - loss: 0.7478\n",
            "Epoch 83/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8873 - loss: 0.7129\n",
            "Epoch 84/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8730 - loss: 0.7023\n",
            "Epoch 85/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8768 - loss: 0.6883\n",
            "Epoch 86/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8972 - loss: 0.6938\n",
            "Epoch 87/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8957 - loss: 0.6583\n",
            "Epoch 88/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8743 - loss: 0.6368\n",
            "Epoch 89/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8912 - loss: 0.5759\n",
            "Epoch 90/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8564 - loss: 0.6415\n",
            "Epoch 91/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8834 - loss: 0.5523\n",
            "Epoch 92/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8902 - loss: 0.5470\n",
            "Epoch 93/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8909 - loss: 0.5559\n",
            "Epoch 94/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8704 - loss: 0.5600\n",
            "Epoch 95/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8820 - loss: 0.5594\n",
            "Epoch 96/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8980 - loss: 0.5084\n",
            "Epoch 97/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8809 - loss: 0.5325\n",
            "Epoch 98/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8782 - loss: 0.5166\n",
            "Epoch 99/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8918 - loss: 0.5028\n",
            "Epoch 100/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8836 - loss: 0.5025\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d9f9fe08650>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "def generate_text(seed_text, next_words):\n",
        "  for _ in range(next_words):\n",
        "\n",
        "    # girdi metnini sayısal hale getir\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "    # padding\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\n",
        "    # prediction\n",
        "    predicted_probabilities = model.predict(token_list, verbose=0)\n",
        "\n",
        "    # en yüksek olasılığa sahip kelimenin indexini bul\n",
        "    predicted_word_index = np.argmax(predicted_probabilities, axis=-1)\n",
        "\n",
        "    # tokenizer ile kelime indexinden asıl kelimeyi bul\n",
        "    predicted_word = tokenizer.index_word[predicted_word_index[0]]\n",
        "\n",
        "    seed_text = seed_text + \" \" + predicted_word\n",
        "\n",
        "  return seed_text"
      ],
      "metadata": {
        "id": "ucFrnUhQD5t-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Bu hafta sonu\"\n",
        "print(generate_text(seed_text, 6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR1ZW9COF3gW",
        "outputId": "aa06e9c2-54ec-4dc0-d08d-42f5542d097a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bu hafta sonu için küçük bir seyahat planı yapıyorum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oKsmTv6kF9ql"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}