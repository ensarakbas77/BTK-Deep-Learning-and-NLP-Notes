{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Metin Üretimi: gpt-2 ile metin üretimi çalışması"
      ],
      "metadata": {
        "id": "jfa0pUYCssi_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AvdVYtWRnLV4"
      },
      "outputs": [],
      "source": [
        "# --- GPT ---\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2\""
      ],
      "metadata": {
        "id": "AhwEa1gFtItM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# model\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "2f2a01c36a2b4f86a7e4546de368afc6",
            "6f9db912c3ef45f29abfb45db8161076",
            "d4bb8d34ca3740d6beb6643f75daa5ff",
            "32776af0a80544cc94dd11ad1c99c696",
            "2df5abca74c242afbc4ff4d7761919a7",
            "c93e994e3c924b7a94a0d3d89d64839c",
            "ac4c32b07bea458497ca968c740d2310",
            "964488d05a6548bd9b42c8675099dba4",
            "0561dc5646494043b7d63b2d3366e33d",
            "d3b729976c54435b9d84f4a97ba46f55",
            "80824798667d4c8aa1c6eb00e82c74d0"
          ]
        },
        "id": "nWMZv65-tcqF",
        "outputId": "16823d30-e074-4fdc-d050-03720e688401"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f2a01c36a2b4f86a7e4546de368afc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# örnek cümle\n",
        "text = \"Afternoon, it was a quiet day and\""
      ],
      "metadata": {
        "id": "wKG1BPeHtmkb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizasyon\n",
        "inputs = tokenizer.encode(text, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "n620z4J2tyAb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metin üretimi\n",
        "outputs = model.generate(inputs, max_length = 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClN-rsQct-1L",
        "outputId": "4f662578-ac69-4ebb-d1b7-8cb06070da17"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modelin ürettiği tokenları okunabilir hale getirelim\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "OBchh0ixuMcb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hENitMjLuq3B",
        "outputId": "9ebccec4-365c-4981-b098-146043d82f2c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Afternoon, it was a quiet day and the sun was shining brightly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- LLAMA ---\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "liCGKS4euzyR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_llama = \"huggyllama/llama-7b\"\n",
        "\n",
        "tokenizer_llama = AutoTokenizer.from_pretrained(model_name_llama)\n",
        "model_llama = AutoModelForCausalLM.from_pretrained(model_name_llama)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3a40bd28b403475dbfdcf20df98b9b0f",
            "678df82e9ae04c019d0c5a3026cdf28d",
            "d88bc4e6eac24213bc0baa9ee45a27c5",
            "7ec42c7c09714ea98fa8c3814dd21b09",
            "0896730c8273431e9d9c9813a789fd4a",
            "2598c55fe49743e4b41be0b19be671ab",
            "ea38449e46bd47f9979fd3d94453c985",
            "2e5867370b294385a695f4296812a391",
            "a55fdac8bb154248a8ab7ec95b10092c",
            "ac567aef8c1a4a0abe7b9f316c5a24c7",
            "bb34549dc0984201bc7e9b185ec9b443"
          ]
        },
        "id": "z71LGFSFvaNC",
        "outputId": "d91c33b1-5848-4b59-a075-939b6c525bab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a40bd28b403475dbfdcf20df98b9b0f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_llama = tokenizer_llama.encode(text, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "qUMNN3eLvsoy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_llama = model_llama.generate(inputs_llama, max_length = 20)"
      ],
      "metadata": {
        "id": "chJDbMWLwHXt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text_llama = tokenizer_llama.decode(outputs_llama[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "-SI9-ErdwOb7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text_llama)"
      ],
      "metadata": {
        "id": "qOUctj6qwUzb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0973c36c-d055-4c14-ccd7-e5e74c2ebc40"
      },
      "execution_count": 30,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Afternoon, it was a quiet day and I was able to get a lot of work done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJvrfQa0UJaL"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}