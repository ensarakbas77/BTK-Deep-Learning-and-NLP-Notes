{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c23294-4f0f-45ca-94ee-c346411c8a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa16983a-3926-4af8-abc0-9d21e0f9302d",
   "metadata": {},
   "source": [
    "## N-Gram Modelleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292b20ab-1c15-4387-a189-3eebf34a2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"I love apple\",\n",
    "    \"I love him\",\n",
    "    \"I love NLP\",\n",
    "    \"You love me\",\n",
    "    \"He loves apple\",\n",
    "    \"They love apple\",\n",
    "    \"I love you and you love me\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3566db52-b6da-40ae-b870-f712221a69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amaç: 1 kelimeden sonra gelecek kelimeyi tahmin etmek -> metin türetmek/oluşturmak\n",
    "# Bunun için N-Gram dil modelini kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5022692-b961-437c-a0b6-4bda1068cb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'love', 'apple'], ['i', 'love', 'him'], ['i', 'love', 'nlp']]\n"
     ]
    }
   ],
   "source": [
    "# Tokenizasyon\n",
    "tokens = [word_tokenize(sentence.lower()) for sentence in corpus]\n",
    "\n",
    "print(tokens[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "198beb40-2add-44c0-b56e-5f652d528b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'love'),\n",
       " ('love', 'apple'),\n",
       " ('i', 'love'),\n",
       " ('love', 'him'),\n",
       " ('i', 'love'),\n",
       " ('love', 'nlp'),\n",
       " ('you', 'love'),\n",
       " ('love', 'me'),\n",
       " ('he', 'loves'),\n",
       " ('loves', 'apple'),\n",
       " ('they', 'love'),\n",
       " ('love', 'apple'),\n",
       " ('i', 'love'),\n",
       " ('love', 'you'),\n",
       " ('you', 'and'),\n",
       " ('and', 'you'),\n",
       " ('you', 'love'),\n",
       " ('love', 'me')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram -> 2 li kelime grupları\n",
    "bigrams = []\n",
    "for token_list in tokens:\n",
    "    bigrams.extend(list(ngrams(token_list, 2)))\n",
    "\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a743e3-beac-4002-baa6-259a493cbc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('i', 'love'): 4,\n",
       "         ('love', 'apple'): 2,\n",
       "         ('you', 'love'): 2,\n",
       "         ('love', 'me'): 2,\n",
       "         ('love', 'him'): 1,\n",
       "         ('love', 'nlp'): 1,\n",
       "         ('he', 'loves'): 1,\n",
       "         ('loves', 'apple'): 1,\n",
       "         ('they', 'love'): 1,\n",
       "         ('love', 'you'): 1,\n",
       "         ('you', 'and'): 1,\n",
       "         ('and', 'you'): 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_freq = Counter(bigrams)\n",
    "bigrams_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67199b72-9634-4d04-9f04-282b38b065ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'love', 'apple'),\n",
       " ('i', 'love', 'him'),\n",
       " ('i', 'love', 'nlp'),\n",
       " ('you', 'love', 'me'),\n",
       " ('he', 'loves', 'apple'),\n",
       " ('they', 'love', 'apple'),\n",
       " ('i', 'love', 'you'),\n",
       " ('love', 'you', 'and'),\n",
       " ('you', 'and', 'you'),\n",
       " ('and', 'you', 'love'),\n",
       " ('you', 'love', 'me')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trigram -> 3 li kelime grupları\n",
    "trigrams = []\n",
    "for token_list in tokens:\n",
    "    trigrams.extend(list(ngrams(token_list, 3)))\n",
    "\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44462a8a-0e57-435c-9571-d92b93f187c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('you', 'love', 'me'): 2,\n",
       "         ('i', 'love', 'apple'): 1,\n",
       "         ('i', 'love', 'him'): 1,\n",
       "         ('i', 'love', 'nlp'): 1,\n",
       "         ('he', 'loves', 'apple'): 1,\n",
       "         ('they', 'love', 'apple'): 1,\n",
       "         ('i', 'love', 'you'): 1,\n",
       "         ('love', 'you', 'and'): 1,\n",
       "         ('you', 'and', 'you'): 1,\n",
       "         ('and', 'you', 'love'): 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_freq = Counter(trigrams)\n",
    "trigrams_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e29a39b-c31f-437c-9a78-a61079a4bfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you kelimesinin olma olasılığı:0.25\n",
      "\n",
      "apple kelimesinin olma olasılığı:0.25\n"
     ]
    }
   ],
   "source": [
    "# I love bigram ından sonra \"you\" ve \"apple\" kelimelerinin gelme olasılıklarını hesaplayalım\n",
    "\n",
    "bigram = (\"i\", \"love\")\n",
    "\n",
    "# \"i love you\" olma olasılığı\n",
    "prob_you = trigrams_freq[(\"i\", \"love\", \"you\")] / bigrams_freq[bigram]\n",
    "print(f\"you kelimesinin olma olasılığı:{prob_you}\\n\")\n",
    "\n",
    "# \"i love apple\" olma olasılığı\n",
    "prob_apple = trigrams_freq[(\"i\", \"love\", \"apple\")] / bigrams_freq[bigram]\n",
    "print(f\"apple kelimesinin olma olasılığı:{prob_apple}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd9ea0c-d69b-4b99-8068-a38198a9e48b",
   "metadata": {},
   "source": [
    "## Hidden Markov Modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e748acc4-b8d5-4b24-b92a-bfa28f990729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part Of Speech (POS): kelimelerin uygun sözcük türünü bulma çalışması\n",
    "\n",
    "from nltk.tag import hmm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d824b45-d7ae-437c-a0fc-849a783579e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    [(\"I\",\"PRP\"),(\"am\",\"VBP\"),(\"a\",\"DT\"),(\"teacher\",\"NN\")],\n",
    "    [(\"You\",\"PRP\"),(\"are\",\"VBP\"),(\"a\",\"DT\"),(\"student\",\"NN\")]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8804580-687e-42d8-9942-d258a8f5ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train HMM\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_tagger = trainer.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89318f50-51ca-4c81-a305-93345823f7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yeni cümle [('I', 'PRP'), ('am', 'VBP'), ('a', 'DT'), ('student', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I am a student\".split()\n",
    "\n",
    "tags = hmm_tagger.tag(test_sentence)\n",
    "print(\"Yeni cümle\",tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41ac8962-a886-4c27-b34f-e3a5223c2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri seti\n",
    "from nltk.corpus import conll2000\n",
    "# nltk.download(\"conll2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ee686b3-9f36-483f-96a0-a2769df05608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: 8936\n",
      "Test Data: 2012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT'), ('pound', 'NN'), ('is', 'VBZ'), ('widely', 'RB'), ('expected', 'VBN'), ('to', 'TO'), ('take', 'VB'), ('another', 'DT'), ('sharp', 'JJ'), ('dive', 'NN'), ('if', 'IN'), ('trade', 'NN'), ('figures', 'NNS'), ('for', 'IN'), ('September', 'NNP'), (',', ','), ('due', 'JJ'), ('for', 'IN'), ('release', 'NN'), ('tomorrow', 'NN'), (',', ','), ('fail', 'VB'), ('to', 'TO'), ('show', 'VB'), ('a', 'DT'), ('substantial', 'JJ'), ('improvement', 'NN'), ('from', 'IN'), ('July', 'NNP'), ('and', 'CC'), ('August', 'NNP'), (\"'s\", 'POS'), ('near-record', 'JJ'), ('deficits', 'NNS'), ('.', '.')]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = conll2000.tagged_sents(\"train.txt\")\n",
    "test_data = conll2000.tagged_sents(\"test.txt\")\n",
    "\n",
    "print(f\"Train Data: {len(train_data)}\")\n",
    "print(f\"Test Data: {len(test_data)}\")\n",
    "\n",
    "train_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "863a59be-c67c-432e-ac85-278441e40bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('like', 'IN'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('school', 'NN')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train HMM\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_tagger = trainer.train(train_data)\n",
    "\n",
    "# Test HMM\n",
    "test_sentence = \"I like going to school\".split()\n",
    "\n",
    "tags = hmm_tagger.tag(test_sentence)\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d35a9b-50b1-456c-8557-ba0c2ef89ff9",
   "metadata": {},
   "source": [
    "POS tagging (sözcük türü etiketleme) işlemini\n",
    "\n",
    "| Etiket | Açılımı                          | Anlamı                              |\n",
    "| ------ | -------------------------------- | ----------------------------------- |\n",
    "| PRP    | Personal Pronoun                 | Ben, sen vb. zamir                  |\n",
    "| IN     | Preposition                      | Edat / Preposition (in, on, at…)    |\n",
    "| VBG    | Verb Gerund / Present Participle | -ing ile biten fiil (going, doing…) |\n",
    "| TO     | “to” kelimesi                    | Fiilden önce gelen “to”             |\n",
    "| NN     | Noun                             | Tekil isim (school, car…)           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff9a04-e7c4-4edd-b453-880d6bdaf821",
   "metadata": {},
   "source": [
    "## Maximum Entropy Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37594d4b-671c-4f39-91b2-779b5a843e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification problem: duygu analizi -> olumlu veya olumsuz olarak sınıflandırma\n",
    "\n",
    "from nltk.classify import MaxentClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d01822be-d0d5-40c2-8516-d43cde6690c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    ({\"love\":True, \"amazing\":True, \"happy\":True, \"terrible\":False}, \"positive\"),\n",
    "    ({\"hate\":True, \"terrible\":True}, \"negative\"),\n",
    "    ({\"joy\":True, \"happy\":True, \"hate\":False}, \"positive\"),\n",
    "    ({\"sad\":True, \"depressed\":True, \"love\":False}, \"negative\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7840baf0-eadd-4dba-ad48-d1726287515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (10 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.500\n",
      "             2          -0.40641        1.000\n",
      "             3          -0.28861        1.000\n",
      "             4          -0.22397        1.000\n",
      "             5          -0.18304        1.000\n",
      "             6          -0.15479        1.000\n",
      "             7          -0.13410        1.000\n",
      "             8          -0.11829        1.000\n",
      "             9          -0.10582        1.000\n",
      "         Final          -0.09573        1.000\n"
     ]
    }
   ],
   "source": [
    "classifier = MaxentClassifier.train(train_data, max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7b40d72-42e2-49ba-a859-31b96d014ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: negative\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I do not like this movie\"\n",
    "\n",
    "features = {word: (word in test_sentence.lower().split()) for word in [\"love\",\"amazing\",\"terrible\",\"happy\",\"joy\",\"sad\",\"depressed\"]}\n",
    "\n",
    "label = classifier.classify(features)\n",
    "print(\"Result:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48100920-5995-4804-b35a-e5bd4bb8eff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
